{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Objective: WAP to train and evaluate a convolutional neural network using Keras Library to classify MNIST fashion dataset. Demonstrate the effect of filter size, regularization, batch size and optimization algorithm on model performance."
      ],
      "metadata": {
        "id": "_9LRw39p89Nd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPUm_NeiuL0B"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Fashion MNIST dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Reshape data to add a single channel (grayscale images)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n"
      ],
      "metadata": {
        "id": "hNyhXuVbuiZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define function to build model\n",
        "def create_model(filter_size=3, regularization=None, optimizer='adam'):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (filter_size, filter_size), activation='relu', input_shape=(28, 28, 1),\n",
        "                      kernel_regularizer=regularization),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Conv2D(64, (filter_size, filter_size), activation='relu', kernel_regularizer=regularization),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularization),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "kPRXNxA9unIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters to experiment with\n",
        "filter_sizes = [3, 5]\n",
        "regularizations = [None, regularizers.l2(0.01)]\n",
        "batch_sizes = [64, 128]\n",
        "optimizers = ['adam', 'sgd']"
      ],
      "metadata": {
        "id": "Gyr993MWur6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate models with different configurations\n",
        "model_count = 1\n",
        "for filter_size in filter_sizes:\n",
        "    for reg in regularizations:\n",
        "        for batch_size in batch_sizes:\n",
        "            for optimizer in optimizers:\n",
        "                model = create_model(filter_size=filter_size, regularization=reg, optimizer=optimizer)\n",
        "                history = model.fit(x_train, y_train, epochs=20, batch_size=batch_size, validation_data=(x_test, y_test), verbose=0)\n",
        "                test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "                train_acc = history.history['accuracy'][-1]\n",
        "                print(f\"Completed {model_count}: filter_size={filter_size}, regularization={reg}, batch_size={batch_size}, optimizer={optimizer}, Train Accuracy={train_acc:.4f}, Test Accuracy={test_acc:.4f}\")\n",
        "                model_count += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNCDVzCDvdRE",
        "outputId": "91793f43-7af2-41bb-9f3c-75d32644a266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 1: filter_size=3, regularization=None, batch_size=64, optimizer=adam, Train Accuracy=0.9103, Test Accuracy=0.9145\n",
            "Completed 2: filter_size=3, regularization=None, batch_size=64, optimizer=sgd, Train Accuracy=0.8278, Test Accuracy=0.8477\n",
            "Completed 3: filter_size=3, regularization=None, batch_size=128, optimizer=adam, Train Accuracy=0.9109, Test Accuracy=0.9142\n",
            "Completed 4: filter_size=3, regularization=None, batch_size=128, optimizer=sgd, Train Accuracy=0.7938, Test Accuracy=0.8173\n",
            "Completed 5: filter_size=3, regularization=<keras.src.regularizers.regularizers.L2 object at 0x7be9ec22ba90>, batch_size=64, optimizer=adam, Train Accuracy=0.8058, Test Accuracy=0.8300\n",
            "Completed 6: filter_size=3, regularization=<keras.src.regularizers.regularizers.L2 object at 0x7be9ec22ba90>, batch_size=64, optimizer=sgd, Train Accuracy=0.8058, Test Accuracy=0.8284\n",
            "Completed 7: filter_size=3, regularization=<keras.src.regularizers.regularizers.L2 object at 0x7be9ec22ba90>, batch_size=128, optimizer=adam, Train Accuracy=0.8081, Test Accuracy=0.8240\n",
            "Completed 8: filter_size=3, regularization=<keras.src.regularizers.regularizers.L2 object at 0x7be9ec22ba90>, batch_size=128, optimizer=sgd, Train Accuracy=0.7860, Test Accuracy=0.8025\n",
            "Completed 9: filter_size=5, regularization=None, batch_size=64, optimizer=adam, Train Accuracy=0.9140, Test Accuracy=0.9147\n",
            "Completed 10: filter_size=5, regularization=None, batch_size=64, optimizer=sgd, Train Accuracy=0.8422, Test Accuracy=0.8595\n",
            "Completed 11: filter_size=5, regularization=None, batch_size=128, optimizer=adam, Train Accuracy=0.9118, Test Accuracy=0.9085\n",
            "Completed 12: filter_size=5, regularization=None, batch_size=128, optimizer=sgd, Train Accuracy=0.8154, Test Accuracy=0.8435\n",
            "Completed 13: filter_size=5, regularization=<keras.src.regularizers.regularizers.L2 object at 0x7be9ec22ba90>, batch_size=64, optimizer=adam, Train Accuracy=0.8369, Test Accuracy=0.8489\n",
            "Completed 14: filter_size=5, regularization=<keras.src.regularizers.regularizers.L2 object at 0x7be9ec22ba90>, batch_size=64, optimizer=sgd, Train Accuracy=0.8158, Test Accuracy=0.8343\n",
            "Completed 15: filter_size=5, regularization=<keras.src.regularizers.regularizers.L2 object at 0x7be9ec22ba90>, batch_size=128, optimizer=adam, Train Accuracy=0.8386, Test Accuracy=0.8612\n",
            "Completed 16: filter_size=5, regularization=<keras.src.regularizers.regularizers.L2 object at 0x7be9ec22ba90>, batch_size=128, optimizer=sgd, Train Accuracy=0.7977, Test Accuracy=0.8224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5epnzo7pvfJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Comments   \n",
        "1) The above CNN architecture is very basic, we can go with more advanced architectures by adding the layers in the model to improve its accuracy.   \n",
        "2) In some cases, the test accuracy is greater than the train accuracy which suggests that the regularization effect or dropout effect is high.    \n",
        "3) We can use the pretrained models like ResNet, EfficientNet, etc which take less time to train the model for Fashion MNIST dataset."
      ],
      "metadata": {
        "id": "CzI6cT0e9KIa"
      }
    }
  ]
}
